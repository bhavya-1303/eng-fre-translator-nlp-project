{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "debCUWCat8H1",
        "outputId": "d7fe4643-0d82-4a68-f1b6-3cecfd11d6e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import pathlib\n",
        "import unicodedata\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Summarization\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "from nltk.tokenize import sent_tokenize\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset\n",
        "url = \"https://storage.googleapis.com/download.tensorflow.org/data/fra-eng.zip\"\n",
        "zip_path = tf.keras.utils.get_file(\n",
        "    \"fra-eng.zip\",\n",
        "    origin=url,\n",
        "    extract=True\n",
        ")\n",
        "\n",
        "# Dynamically locate fra.txt\n",
        "base_dir = pathlib.Path(zip_path).parent\n",
        "fra_txt = None\n",
        "\n",
        "for root, dirs, files in os.walk(base_dir):\n",
        "    if \"fra.txt\" in files:\n",
        "        fra_txt = pathlib.Path(root) / \"fra.txt\"\n",
        "        break\n",
        "\n",
        "if fra_txt is None:\n",
        "    raise FileNotFoundError(\"fra.txt not found!\")\n",
        "\n",
        "print(\"Dataset found at:\", fra_txt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbQSExtAvMmd",
        "outputId": "993df65c-ef8d-4bef-a8ba-31e1e2c96b5a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/fra-eng.zip\n",
            "\u001b[1m3423204/3423204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Dataset found at: /root/.keras/datasets/fra-eng_extracted/fra.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(line):\n",
        "    line = unicodedata.normalize(\"NFKC\", line.strip().lower())\n",
        "    eng, fre = line.split(\"\\t\")\n",
        "    fre = \"[start] \" + fre + \" [end]\"\n",
        "    return eng, fre\n"
      ],
      "metadata": {
        "id": "Y67Vwy0vw6L4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(fra_txt, encoding=\"utf-8\") as f:\n",
        "    text_pairs = [normalize(line) for line in f]\n",
        "\n",
        "random.shuffle(text_pairs)\n",
        "print(\"Total sentence pairs:\", len(text_pairs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7rs_ZjXw7sG",
        "outputId": "e4953a1a-2b27-426c-a81e-ed730faebb02"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sentence pairs: 167130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_val = int(0.15 * len(text_pairs))\n",
        "train_pairs = text_pairs[:-n_val]\n",
        "val_pairs = text_pairs[-n_val:]\n"
      ],
      "metadata": {
        "id": "YjNb5HDXw-pW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_en = 10000\n",
        "vocab_fr = 20000\n",
        "seq_length = 25\n",
        "\n",
        "eng_vect = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=vocab_en,\n",
        "    split=\"whitespace\",\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=seq_length\n",
        ")\n",
        "\n",
        "fre_vect = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=vocab_fr,\n",
        "    split=\"whitespace\",\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=seq_length + 1\n",
        ")\n",
        "\n",
        "eng_vect.adapt([p[0] for p in train_pairs])\n",
        "fre_vect.adapt([p[1] for p in train_pairs])\n"
      ],
      "metadata": {
        "id": "0DQxkbp7xCHq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_dataset(eng, fre):\n",
        "    eng = eng_vect(eng)\n",
        "    fre = fre_vect(fre)\n",
        "    return (\n",
        "        {\"encode_inp\": eng, \"decode_inp\": fre[:, :-1]},\n",
        "        fre[:, 1:]\n",
        "    )\n",
        "\n",
        "def make_dataset(pairs, batch_size=64):\n",
        "    eng, fre = zip(*pairs)\n",
        "    ds = tf.data.Dataset.from_tensor_slices((list(eng), list(fre)))\n",
        "    ds = ds.shuffle(2048).batch(batch_size)\n",
        "    ds = ds.map(format_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)\n"
      ],
      "metadata": {
        "id": "gYlqA8_oxGgr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, seq_len, vocab_size, embed_dim):\n",
        "        super().__init__()\n",
        "        self.token_emb = tf.keras.layers.Embedding(\n",
        "            vocab_size, embed_dim, mask_zero=True\n",
        "        )\n",
        "\n",
        "        pos = np.arange(seq_len)[:, None]\n",
        "        i = np.arange(embed_dim)[None, :]\n",
        "        angle = pos / np.power(10000, (2 * (i // 2)) / embed_dim)\n",
        "        angle[:, 0::2] = np.sin(angle[:, 0::2])\n",
        "        angle[:, 1::2] = np.cos(angle[:, 1::2])\n",
        "\n",
        "        self.pos_emb = tf.constant(angle, dtype=tf.float32)\n",
        "\n",
        "    def call(self, x):\n",
        "        return self.token_emb(x) + self.pos_emb\n"
      ],
      "metadata": {
        "id": "r_YzVrwXxJSu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, heads, ff_dim):\n",
        "        super().__init__()\n",
        "        self.att = tf.keras.layers.MultiHeadAttention(heads, embed_dim)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(ff_dim, activation=\"relu\"),\n",
        "            tf.keras.layers.Dense(embed_dim)\n",
        "        ])\n",
        "        self.norm1 = tf.keras.layers.LayerNormalization()\n",
        "        self.norm2 = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.norm1(x + self.att(x, x))\n",
        "        return self.norm2(x + self.ffn(x))\n"
      ],
      "metadata": {
        "id": "_k-_s8sYxMMh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, heads, ff_dim):\n",
        "        super().__init__()\n",
        "        self.self_att = tf.keras.layers.MultiHeadAttention(heads, embed_dim)\n",
        "        self.cross_att = tf.keras.layers.MultiHeadAttention(heads, embed_dim)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(ff_dim, activation=\"relu\"),\n",
        "            tf.keras.layers.Dense(embed_dim)\n",
        "        ])\n",
        "        self.norm1 = tf.keras.layers.LayerNormalization()\n",
        "        self.norm2 = tf.keras.layers.LayerNormalization()\n",
        "        self.norm3 = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "    def call(self, x, enc):\n",
        "        x = self.norm1(x + self.self_att(x, x, use_causal_mask=True))\n",
        "        x = self.norm2(x + self.cross_att(x, enc))\n",
        "        return self.norm3(x + self.ffn(x))\n"
      ],
      "metadata": {
        "id": "QzGV8e1uxS0R"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_transformer():\n",
        "    enc_in = tf.keras.Input(shape=(seq_length,), name=\"encode_inp\")\n",
        "    dec_in = tf.keras.Input(shape=(seq_length,), name=\"decode_inp\")\n",
        "\n",
        "    enc = PositionalEmbedding(seq_length, vocab_en, 128)(enc_in)\n",
        "    dec = PositionalEmbedding(seq_length, vocab_fr, 128)(dec_in)\n",
        "\n",
        "    for _ in range(4):\n",
        "        enc = EncoderBlock(128, 4, 512)(enc)\n",
        "        dec = DecoderBlock(128, 4, 512)(dec, enc)\n",
        "\n",
        "    out = tf.keras.layers.Dense(vocab_fr)(dec)\n",
        "    return tf.keras.Model([enc_in, dec_in], out)\n",
        "\n",
        "model = build_transformer()\n"
      ],
      "metadata": {
        "id": "42AGHdhsx93r"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_loss(y_true, y_pred):\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "        y_true, y_pred, from_logits=True\n",
        "    )\n",
        "    return tf.reduce_sum(loss * mask) / tf.reduce_sum(mask)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    loss=masked_loss,\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        },
        "id": "9DHQ0ShTyEiL",
        "outputId": "82fa05e2-80a7-4bdb-a3f1-14fddca6fcb5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encode_inp          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decode_inp          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m1,280,000\u001b[0m │ encode_inp[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m2,560,000\u001b[0m │ decode_inp[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_block       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m396,032\u001b[0m │ positional_embed… │\n",
              "│ (\u001b[38;5;33mEncoderBlock\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_block       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m660,096\u001b[0m │ positional_embed… │\n",
              "│ (\u001b[38;5;33mDecoderBlock\u001b[0m)      │                   │            │ encoder_block[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_block_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m396,032\u001b[0m │ encoder_block[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEncoderBlock\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_block_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m660,096\u001b[0m │ decoder_block[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mDecoderBlock\u001b[0m)      │                   │            │ encoder_block_1[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_block_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m396,032\u001b[0m │ encoder_block_1[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mEncoderBlock\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_block_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m660,096\u001b[0m │ decoder_block_1[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mDecoderBlock\u001b[0m)      │                   │            │ encoder_block_2[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_block_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m396,032\u001b[0m │ encoder_block_2[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mEncoderBlock\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_block_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m660,096\u001b[0m │ decoder_block_2[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mDecoderBlock\u001b[0m)      │                   │            │ encoder_block_3[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m20000\u001b[0m) │  \u001b[38;5;34m2,580,000\u001b[0m │ decoder_block_3[\u001b[38;5;34m…\u001b[0m │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encode_inp          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decode_inp          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │ encode_inp[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,000</span> │ decode_inp[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_block       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">396,032</span> │ positional_embed… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">EncoderBlock</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_block       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">660,096</span> │ positional_embed… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>)      │                   │            │ encoder_block[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_block_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">396,032</span> │ encoder_block[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">EncoderBlock</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_block_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">660,096</span> │ decoder_block[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>)      │                   │            │ encoder_block_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_block_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">396,032</span> │ encoder_block_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">EncoderBlock</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_block_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">660,096</span> │ decoder_block_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>)      │                   │            │ encoder_block_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_block_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">396,032</span> │ encoder_block_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">EncoderBlock</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_block_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">660,096</span> │ decoder_block_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>)      │                   │            │ encoder_block_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,580,000</span> │ decoder_block_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,644,512\u001b[0m (40.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,644,512</span> (40.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,644,512\u001b[0m (40.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,644,512</span> (40.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=5   # increase to 20 for final run\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a32ogSAYyHen",
        "outputId": "3e5fcdb6-0bbf-40af-f99f-46ad1c1b3eda"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 68ms/step - accuracy: 0.0538 - loss: 6.5974 - val_accuracy: 0.1083 - val_loss: 4.0249\n",
            "Epoch 2/5\n",
            "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 61ms/step - accuracy: 0.1212 - loss: 3.7392 - val_accuracy: 0.1524 - val_loss: 2.9148\n",
            "Epoch 3/5\n",
            "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 61ms/step - accuracy: 0.1598 - loss: 2.7795 - val_accuracy: 0.1787 - val_loss: 2.3456\n",
            "Epoch 4/5\n",
            "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 60ms/step - accuracy: 0.1842 - loss: 2.2111 - val_accuracy: 0.1917 - val_loss: 1.9971\n",
            "Epoch 5/5\n",
            "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 61ms/step - accuracy: 0.1990 - loss: 1.8338 - val_accuracy: 0.2002 - val_loss: 1.7601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(sentence):\n",
        "    enc = eng_vect([sentence])\n",
        "    result = [\"[start]\"]\n",
        "    vocab = fre_vect.get_vocabulary()\n",
        "\n",
        "    for _ in range(seq_length):\n",
        "        dec = fre_vect([\" \".join(result)])[:, :-1]\n",
        "        preds = model([enc, dec])\n",
        "        token = tf.argmax(preds[0, len(result)-1]).numpy()\n",
        "        word = vocab[token]\n",
        "        result.append(word)\n",
        "        if word == \"[end]\":\n",
        "            break\n",
        "\n",
        "    return \" \".join(result)\n"
      ],
      "metadata": {
        "id": "A1tkjG5iyVKg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_text(text, num_sentences=2):\n",
        "    sentences = sent_tokenize(text)\n",
        "    if len(sentences) <= num_sentences:\n",
        "        return text\n",
        "\n",
        "    vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
        "    tfidf = vectorizer.fit_transform(sentences)\n",
        "    scores = tfidf.sum(axis=1).A1\n",
        "\n",
        "    ranked = sorted(\n",
        "        ((score, sent) for score, sent in zip(scores, sentences)),\n",
        "        reverse=True\n",
        "    )\n",
        "\n",
        "    selected = [s for _, s in ranked[:num_sentences]]\n",
        "    return \" \".join([s for s in sentences if s in selected])\n"
      ],
      "metadata": {
        "id": "_14t8ApbygLn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "def ensure_nltk():\n",
        "    for pkg in [\"punkt\", \"punkt_tab\"]:\n",
        "        try:\n",
        "            nltk.data.find(f\"tokenizers/{pkg}\")\n",
        "        except LookupError:\n",
        "            nltk.download(pkg)\n",
        "\n",
        "ensure_nltk()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkuGtZy8Mi-K",
        "outputId": "7e2583cd-39d9-4ae5-d364-10a5f0ff9e48"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_and_translate(text):\n",
        "    summary = summarize_text(text)\n",
        "    translation = translate(summary)\n",
        "    return summary, translation\n"
      ],
      "metadata": {
        "id": "yqeLyl9hyiIY"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "e, f = random.choice(text_pairs)\n",
        "print(\"English :\", e)\n",
        "print(\"Predicted:\", translate(e))\n",
        "print(\"Actual FR:\", f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzfr4F7Mykxb",
        "outputId": "fbe9eee8-dc3b-4938-acfc-48bfd1d0036b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English : tom shook my hand.\n",
            "Predicted: [start] tom ma montré ma main end end end end end end end end end end end end end end end end end end end end\n",
            "Actual FR: [start] tom me serra la main. [end]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "Transformers are deep learning models that have revolutionized natural language processing.\n",
        "They are widely used in translation and summarization tasks.\n",
        "\"\"\"\n",
        "\n",
        "summary, french = summarize_and_translate(text)\n",
        "print(\"\\nSUMMARY:\\n\", summary)\n",
        "print(\"\\nFRENCH TRANSLATION:\\n\", french)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcuHR0yRym-R",
        "outputId": "633eb2af-4946-4ed6-8310-c113cfba5fd0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SUMMARY:\n",
            " \n",
            "Transformers are deep learning models that have revolutionized natural language processing.\n",
            "They are widely used in translation and summarization tasks.\n",
            "\n",
            "\n",
            "FRENCH TRANSLATION:\n",
            " [start] les [UNK] [UNK] [UNK] que la langue [UNK] [UNK] des [UNK] [UNK] sont des [UNK] et ils sont des [UNK] end end end end de\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Interactive English → French Translation\n",
        "while True:\n",
        "    user_input = input(\"\\nEnter an English sentence (or type 'exit'): \")\n",
        "\n",
        "    if user_input.lower() == \"exit\":\n",
        "        print(\"Exiting translator.\")\n",
        "        break\n",
        "\n",
        "    translation = translate(user_input)\n",
        "\n",
        "    print(\"\\nFrench Translation:\")\n",
        "    print(translation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-Imgs1gypmJ",
        "outputId": "0517e0ab-c660-438d-a1c4-62e46e05d26d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enter an English sentence (or type 'exit'): hello \n",
            "\n",
            "French Translation:\n",
            "[start] cest juste end end end end end end end end end end end end end end end end end end end end end end end\n",
            "\n",
            "Enter an English sentence (or type 'exit'): hloo\n",
            "\n",
            "French Translation:\n",
            "[start] [UNK] end end end end end end end end end end end end end end end end end end end end end end end end\n",
            "\n",
            "Enter an English sentence (or type 'exit'): hi this is bhavya\n",
            "\n",
            "French Translation:\n",
            "[start] ferme cest [UNK] end end end end end end end end end end end end end end end end end end end end end end\n",
            "\n",
            "Enter an English sentence (or type 'exit'): exit\n",
            "Exiting translator.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Interactive Summarize + Translate\n",
        "while True:\n",
        "    user_input = input(\"\\nEnter an English paragraph (or 'exit'): \")\n",
        "\n",
        "    if user_input.lower() == \"exit\":\n",
        "        print(\"Exiting summarizer.\")\n",
        "        break\n",
        "\n",
        "    summary, french = summarize_and_translate(user_input)\n",
        "\n",
        "    print(\"\\nSummary:\")\n",
        "    print(summary)\n",
        "\n",
        "    print(\"\\nFrench Translation:\")\n",
        "    print(french)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qV2G9iG0y8jL",
        "outputId": "8b2a100b-9063-4f01-b405-a82fd8b3d111"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enter an English paragraph (or 'exit'): hi my name is sai im studying bttech\n",
            "\n",
            "Summary:\n",
            "hi my name is sai im studying bttech\n",
            "\n",
            "French Translation:\n",
            "[start] malheureusement mon nom est [UNK] [UNK] les [UNK] end end end end end end end end end end end end end end end end end\n",
            "\n",
            "Enter an English paragraph (or 'exit'): exit\n",
            "Exiting summarizer.\n"
          ]
        }
      ]
    }
  ]
}